import streamlit as st
import pandas as pd
import random
import json
import requests
import time
import hashlib
import os
import base64
import string
from datetime import date
from google.cloud import firestore
from google.oauth2 import service_account
from streamlit.components.v1 import html

# --- æ–°å¢ï¼šå˜—è©¦åŒ¯å…¥ SpeechRecognition (ä¿ç•™ä¾›å…¶ä»–ç”¨é€”ï¼Œä½†ä¸»åŠŸèƒ½æ”¹ç”¨ Gemini Audio) ---
try:
    import speech_recognition as sr
except ImportError:
    sr = None

# --- 0. è¨­å®šèˆ‡å¸¸æ•¸ ---
st.set_page_config(page_title="Flashcard Pro é›²ç«¯ç‰ˆ", page_icon="app-icon.png", layout="wide")

# è®€å– Secrets
GEMINI_API_KEY = st.secrets.get("GEMINI_API_KEY", "")
GEMINI_MODEL = "gemini-2.5-flash-preview-09-2025"
GEMINI_API_URL = f"https://generativelanguage.googleapis.com/v1beta/models/{GEMINI_MODEL}:generateContent"

# é è¨­å–®å­—å…§å®¹ (Fallback)
INITIAL_VOCAB = [
    {"English": "plus", "POS": "ä»‹ç³»è©", "Chinese_1": "åŠ ", "Chinese_2": "åŠ ä¸Š", "Example": "Two plus two is four.", "Course": "Sophieæ•¸å­¸èª²", "Date": "2025-11-15", "Correct": 0, "Total": 0},
    {"English": "minus", "POS": "ä»‹ç³»è©", "Chinese_1": "æ¸›", "Chinese_2": "æ¸›å»", "Example": "Five minus two is three.", "Course": "Sophieæ•¸å­¸èª²", "Date": "2025-11-15", "Correct": 0, "Total": 0},
    {"English": "multiply", "POS": "å‹•è©", "Chinese_1": "ä¹˜", "Chinese_2": "ç¹æ®–", "Example": "Multiply 3 by 4.", "Course": "Sophieæ•¸å­¸èª²", "Date": "2025-12-31", "Correct": 0, "Total": 0},
    {"English": "divide", "POS": "å‹•è©", "Chinese_1": "é™¤", "Chinese_2": "åˆ†é–‹", "Example": "Divide 10 by 2.", "Course": "Sophieæ•¸å­¸èª²", "Date": "2026-01-10", "Correct": 0, "Total": 0},
    {"English": "think", "POS": "å‹•è©", "Chinese_1": "æ€è€ƒ", "Chinese_2": "æƒ³", "Example": "I need to think about it.", "Course": "Cherieæ€è€ƒèª²", "Date": "2025-11-16", "Correct": 0, "Total": 0},
]

# é è¨­å¥å‹å…§å®¹ (Fallback)
INITIAL_SENTENCES = [
    {"Category": "1.åŸºç¤æè¿°å¥", "Template": "This ___ is very important.", "Options": ["test", "rule", "decision", "habit", "lesson"]},
    {"Category": "1.åŸºç¤æè¿°å¥", "Template": "This ___ is very expensive.", "Options": ["course", "phone", "trip", "book", "gift"]},
]

# --- 1. Firestore åˆå§‹åŒ– ---
@st.cache_resource
def get_db():
    try:
        creds_info = st.secrets["firebase_credentials"]
        creds = service_account.Credentials.from_service_account_info(creds_info)
        return firestore.Client(credentials=creds)
    except Exception as e:
        return None

db = get_db()
APP_ID = st.secrets.get("APP_ID", "flashcard-pro-v1")
USER_LIST_PATH = f"artifacts/{APP_ID}/public/data/users"
SENTENCE_CATALOG_PATH = f"artifacts/{APP_ID}/public/data/sentences"
SENTENCE_DATA_BASE_PATH = f"artifacts/{APP_ID}/public/data"

# --- 2. å·¥å…·å‡½å¼ ---

def hash_string(text):
    return hashlib.md5(text.encode('utf-8')).hexdigest()

def hash_password(password):
    return hashlib.sha256(password.encode()).hexdigest()

@st.cache_data(ttl=600)
def fetch_users_list():
    if not db: return {}
    docs = db.collection(USER_LIST_PATH).stream()
    return {d.id: d.to_dict() for d in docs}

def init_users_in_db():
    if not db: return
    if st.session_state.get("users_initialized"): return
    docs = db.collection(USER_LIST_PATH).limit(1).get()
    if not docs:
        default_pwd = hash_password("1234")
        users = [
            {"name": "Esme", "id": "S001", "password": default_pwd, "color": "#FF69B4"},
            {"name": "Neo", "id": "S002", "password": default_pwd, "color": "#1E90FF"},
            {"name": "Verno", "id": "S003", "password": default_pwd, "color": "#32CD32"}
        ]
        for u in users:
            db.collection(USER_LIST_PATH).document(u["name"]).set(u)
    st.session_state.users_initialized = True

# --- 3. Session State åˆå§‹åŒ– ---
if "logged_in" not in st.session_state:
    st.session_state.logged_in = False
if "user_info" not in st.session_state:
    st.session_state.user_info = None
if "u_vocab" not in st.session_state:
    st.session_state.u_vocab = []
if "practice_idx" not in st.session_state:
    st.session_state.practice_idx = 0
if "practice_reveal" not in st.session_state:
    st.session_state.practice_reveal = False
if "quiz_history" not in st.session_state:
    st.session_state.quiz_history = []
if "audio_to_play" not in st.session_state:
    st.session_state.audio_to_play = None
# å°èˆªç‹€æ…‹ç®¡ç†
if "nav_selection" not in st.session_state:
    st.session_state.nav_selection = "å­¸ç¿’å„€è¡¨æ¿"

# å¥å‹ç·´ç¿’å°ˆç”¨ State
if "sentence_idx" not in st.session_state:
    st.session_state.sentence_idx = 0
if "completed_options" not in st.session_state:
    st.session_state.completed_options = set() 
if "current_sentences" not in st.session_state:
    st.session_state.current_sentences = []
if "last_sentence_filter_sig" not in st.session_state:
    st.session_state.last_sentence_filter_sig = ""
if "current_dataset_id" not in st.session_state:
    st.session_state.current_dataset_id = None # è¨˜éŒ„ç•¶å‰æ­£åœ¨ç·´ç¿’å“ªå€‹é¡Œåº«

init_users_in_db()

# --- 4. è³‡æ–™åº«æ“ä½œå‡½å¼ (å–®å­— & å¥å‹) ---

def get_vocab_path():
    if st.session_state.logged_in and st.session_state.user_info:
        uid = st.session_state.user_info["id"]
        return f"artifacts/{APP_ID}/users/{uid}/vocabulary"
    return None

def get_sentence_progress_path():
    if st.session_state.logged_in and st.session_state.user_info:
        uid = st.session_state.user_info["id"]
        return f"artifacts/{APP_ID}/users/{uid}/sentence_progress"
    return None

def sync_vocab_from_db(init_if_empty=False):
    path = get_vocab_path()
    if not db or not path: return
    docs = db.collection(path).stream()
    data = []
    for d in docs:
        item = d.to_dict()
        item['id'] = d.id
        data.append(item)
    
    if not data and init_if_empty:
        for item in INITIAL_VOCAB:
            db.collection(path).add(item)
        time.sleep(1)
        return sync_vocab_from_db(init_if_empty=False)
        
    st.session_state.u_vocab = data

def update_word_data(doc_id, update_dict):
    path = get_vocab_path()
    if db and path and doc_id:
        db.collection(path).document(doc_id).update(update_dict)
        for item in st.session_state.u_vocab:
            if item.get('id') == doc_id:
                item.update(update_dict)
                break

def save_new_words_to_db(items):
    path = get_vocab_path()
    if db and path:
        batch = db.batch()
        count = 0
        for it in items:
            doc_ref = db.collection(path).document()
            batch.set(doc_ref, it)
            count += 1
            if count >= 400:
                batch.commit()
                batch = db.batch()
                count = 0
        if count > 0:
            batch.commit()

def delete_words_from_db(doc_ids):
    path = get_vocab_path()
    if db and path:
        for doc_id in doc_ids:
            db.collection(path).document(doc_id).delete()

# --- å¥å‹è³‡æ–™åº«æ“ä½œ ---

@st.cache_data(ttl=600)
def fetch_sentence_catalogs():
    """è®€å–å…¬ç”¨é¡Œåº«åˆ—è¡¨"""
    if not db: return {}
    docs = db.collection(SENTENCE_CATALOG_PATH).stream()
    return {d.id: d.to_dict().get('name', d.id) for d in docs}

@st.cache_data(ttl=600)
def fetch_sentences_by_id(dataset_id):
    """è®€å–ç‰¹å®šé¡Œåº«çš„å¥å‹ï¼Œä¸¦ä¾ç…§ Order æ’åº"""
    if not db: return []
    path = f"{SENTENCE_DATA_BASE_PATH}/{dataset_id}"
    docs = db.collection(path).stream()
    data = [d.to_dict() for d in docs]
    sorted_data = sorted(data, key=lambda x: x.get('Order', 9999))
    return sorted_data

def load_user_sentence_progress(template_hash):
    path = get_sentence_progress_path()
    if not db or not path: return []
    doc = db.collection(path).document(template_hash).get()
    if doc.exists:
        return set(doc.to_dict().get("completed_options", []))
    return set()

def fetch_all_user_sentence_progress():
    path = get_sentence_progress_path()
    if not db or not path: return {}
    docs = db.collection(path).stream()
    return {d.id: d.to_dict().get("completed_options", []) for d in docs}

# --- æ–°å¢ï¼šæ›´æ–°ä½¿ç”¨è€…çµ±è¨ˆæ‘˜è¦ ---
def update_user_stats_summary(dataset_id):
    """è¨ˆç®—ä¸¦æ›´æ–°ä½¿ç”¨è€…çš„è©²é¡Œåº«çµ±è¨ˆè³‡è¨Š"""
    if not db or not dataset_id: return
    user_name = st.session_state.get("current_user_name")
    if not user_name: return

    # 1. å–å¾—é¡Œåº«è³‡è¨Š (åˆ©ç”¨å¿«å–)
    sentences = fetch_sentences_by_id(dataset_id)
    catalogs = fetch_sentence_catalogs()
    dataset_name = catalogs.get(dataset_id, dataset_id)
    
    total_count = len(sentences)
    if total_count == 0: return

    # 2. å–å¾—ä½¿ç”¨è€…åœ¨è©²é¡Œåº«çš„æ‰€æœ‰é€²åº¦
    # é€™è£¡ç›´æ¥æŸ¥è©¢ Firestoreï¼Œå› ç‚ºéœ€è¦æœ€æ–°æ•¸æ“š
    progress_path = get_sentence_progress_path()
    docs = db.collection(progress_path).where("dataset_id", "==", dataset_id).stream()
    
    progress_map = {}
    for d in docs:
        data = d.to_dict()
        progress_map[d.id] = set(data.get("completed_options", []))
        
    completed_count = 0
    in_progress_count = 0
    
    for s in sentences:
        tid = hash_string(s['Template'])
        user_done = progress_map.get(tid, set())
        all_opts = set(s.get('Options', []))
        
        if not all_opts: continue
        
        if user_done:
            if all_opts.issubset(user_done):
                completed_count += 1
            else:
                in_progress_count += 1
    
    # 3. æ›´æ–°ä½¿ç”¨è€…æ–‡ä»¶
    # çµæ§‹: sentence_stats: { dataset_id: { ... } }
    user_ref = db.collection(USER_LIST_PATH).document(user_name)
    stats_data = {
        f"sentence_stats.{dataset_id}": {
            "name": dataset_name,
            "total": total_count,
            "completed": completed_count,
            "in_progress": in_progress_count,
            "last_active": firestore.SERVER_TIMESTAMP
        }
    }
    user_ref.update(stats_data)
    # æ¸…é™¤å¿«å–ï¼Œç¢ºä¿æ’è¡Œæ¦œæ›´æ–°
    fetch_users_list.clear()

def save_user_sentence_progress(template_str, completed_list, dataset_id=None):
    """å„²å­˜ä½¿ç”¨è€…å°æŸå¥å‹çš„ç·´ç¿’é€²åº¦ï¼Œä¸¦æ¨™è¨˜ä¾†æºé¡Œåº« ID"""
    path = get_sentence_progress_path()
    if not db or not path: return
    template_hash = hash_string(template_str)
    data = {
        "template_text": template_str,
        "completed_options": list(completed_list),
        "last_updated": firestore.SERVER_TIMESTAMP
    }
    # æ–°å¢ï¼šè¨˜éŒ„é€™æ˜¯å“ªæœ¬é¡Œåº«çš„é€²åº¦ï¼Œæ–¹ä¾¿æ—¥å¾Œç®¡ç†
    if dataset_id:
        data["dataset_id"] = dataset_id
        
    db.collection(path).document(template_hash).set(data, merge=True)
    
    # åŒæ­¥æ›´æ–°çµ±è¨ˆæ‘˜è¦
    if dataset_id:
        update_user_stats_summary(dataset_id)

def clear_user_sentence_history(target_dataset_id=None):
    """
    æ¸…é™¤è©²ä½¿ç”¨è€…æ‰€æœ‰çš„å¥å‹ç·´ç¿’ç´€éŒ„ã€‚
    å¦‚æœæŒ‡å®šäº† target_dataset_idï¼Œåªæ¸…é™¤è©²é¡Œåº«çš„ç´€éŒ„ã€‚
    """
    path = get_sentence_progress_path()
    if not db or not path: return 0

    # æ‰¹æ¬¡åˆªé™¤ sentence_progress
    docs = db.collection(path).stream()
    batch = db.batch()
    count = 0
    deleted_count = 0

    for d in docs:
        doc_data = d.to_dict()
        # å¦‚æœæŒ‡å®šäº†é¡Œåº«IDï¼Œä¸”è©²è¨˜éŒ„ä¸å±¬æ–¼æ­¤é¡Œåº«ï¼Œå‰‡è·³é
        if target_dataset_id and doc_data.get("dataset_id") != target_dataset_id:
            continue

        batch.delete(d.reference)
        count += 1
        deleted_count += 1
        if count >= 400:
            batch.commit()
            batch = db.batch()
            count = 0
    if count > 0:
        batch.commit()

    # æ¸…é™¤ users æ–‡ä»¶ä¸­çš„ sentence_stats
    user_name = st.session_state.get("current_user_name")
    if user_name:
        user_ref = db.collection(USER_LIST_PATH).document(user_name)
        if target_dataset_id:
            # åªåˆªé™¤ç‰¹å®šé¡Œåº«çš„çµ±è¨ˆ
            user_ref.update({
                f"sentence_stats.{target_dataset_id}": firestore.DELETE_FIELD
            })
        else:
            # åˆªé™¤æ‰€æœ‰ sentence_stats
            user_ref.update({
                "sentence_stats": firestore.DELETE_FIELD
            })
        fetch_users_list.clear()  # æ¸…é™¤å¿«å–

    return deleted_count

# --- 5. AI èˆ‡ JS å·¥å…· ---

def normalize_text(text):
    if not text: return ""
    text = text.translate(str.maketrans('', '', string.punctuation))
    return " ".join(text.split()).lower()

def check_audio_batch(audio_file, template, options_list):
    """
    æ‰¹æ¬¡èªéŸ³æª¢æŸ¥ï¼š
    1. å„ªå…ˆä½¿ç”¨ Gemini (å¤šæ¨¡æ…‹) è™•ç†éŸ³è¨Š + è½‰éŒ„ + åˆ¤æ–·ã€‚
    2. å¦‚æœ Gemini æ²’æŠ“åˆ°ä»»ä½•é¸é … (correct_options ç‚ºç©º) æˆ–å¤±æ•—ï¼Œæ‰ä½¿ç”¨ SpeechRecognition (SR) åš Fallbackã€‚
    """
    # --- æº–å‚™ï¼šè®€å– Prompt æª”æ¡ˆ ---
    prompt_file = "pronunciation_feedback_prompt.md"
    base_prompt = ""
    if os.path.exists(prompt_file):
        with open(prompt_file, "r", encoding="utf-8") as f:
            base_prompt = f.read()
    else:
        # Fallback prompt if file is missing
        base_prompt = """
        Context: English pronunciation practice for non-native speakers.
        Template Sentence: "{template}"
        Target Vocabulary to fill in the blank: {options_list}
        
        Task:
        1. Listen to the audio provided.
        2. Transcribe it exactly as heard.
        3. Identify which of the 'Target Vocabulary' appear in the speech within the sentence structure.
        4. Be flexible with minor pronunciation errors, but key words must be recognizable.
        5. Provide specific, constructive feedback in Traditional Chinese.

        Return JSON: 
        {{ 
            "transcript": "Transcription of the audio",
            "correct_options": ["opt1", "opt2"], 
            "feedback": "Specific feedback here" 
        }}
        """

    # å¡«å…¥ Prompt è®Šæ•¸
    prompt = base_prompt.format(
        template=template,
        options_list=options_list
    )

    # è®€å–éŸ³è¨Š Bytes
    audio_file.seek(0)
    audio_bytes = audio_file.read()
    encoded_audio = base64.b64encode(audio_bytes).decode('utf-8')
    
    # --- å˜—è©¦ 1ï¼šGemini å¤šæ¨¡æ…‹ (éŸ³è¨Šç›´æ¥è¼¸å…¥) ---
    ai_corrects = []
    ai_transcript = ""
    ai_feedback = ""
    gemini_success = False
    
    gemini_payload = {
        "contents": [{
            "parts": [
                {"text": prompt},
                {"inline_data": {"mime_type": "audio/wav", "data": encoded_audio}}
            ]
        }],
        "generationConfig": {"responseMimeType": "application/json"}
    }
    
    try:
        res = requests.post(f"{GEMINI_API_URL}?key={GEMINI_API_KEY}", json=gemini_payload, timeout=30)
        if res.status_code == 200:
            content_text = res.json()['candidates'][0]['content']['parts'][0]['text']
            
            # æ¸…ç† JSON å­—ä¸²
            if "```json" in content_text:
                content_text = content_text.split("```json")[1].split("```")[0]
            elif "```" in content_text:
                content_text = content_text.split("```")[1].split("```")[0]
            
            ai_result = json.loads(content_text.strip())
            
            ai_transcript = ai_result.get("transcript", "")
            ai_feedback = ai_result.get("feedback", "åŠ æ²¹ï¼")
            
            # è™•ç†å¤§å°å¯«
            raw_ai_found = ai_result.get("correct_options", [])
            options_lower_map = {opt.lower(): opt for opt in options_list}
            for raw_opt in raw_ai_found:
                if raw_opt in options_list:
                    ai_corrects.append(raw_opt)
                elif raw_opt.lower() in options_lower_map:
                    ai_corrects.append(options_lower_map[raw_opt.lower()])
            
            gemini_success = True
            
    except Exception as e:
        print(f"Gemini Audio Error: {e}")

    # å¦‚æœ Gemini æˆåŠŸä¸”æœ‰æŠ“åˆ°æ±è¥¿ï¼Œç›´æ¥å›å‚³
    if gemini_success and ai_corrects:
        return {
            "correct_options": ai_corrects,
            "heard": ai_transcript,
            "feedback": ai_feedback
        }

    # --- å˜—è©¦ 2ï¼šFallback (æœ¬åœ° SR + å­—ä¸²æ¯”å°) ---
    # ç•¶ Gemini æ²’æŠ“åˆ° (ai_corrects ç‚ºç©º) æˆ– é€£ç·šå¤±æ•— æ™‚åŸ·è¡Œ
    
    # ç¢ºä¿æœ‰å®‰è£ SR
    if sr:
        audio_file.seek(0) # é‡ç½®æŒ‡é‡
        recognizer = sr.Recognizer()
        local_transcript = ""
        try:
            with sr.AudioFile(audio_file) as source:
                audio_data = recognizer.record(source)
            local_transcript = recognizer.recognize_google(audio_data, language="en-US")
        except:
            pass # SR å¤±æ•—å°±ç¶­æŒç©ºå­—ä¸²

        if local_transcript:
            local_found = []
            norm_transcript = normalize_text(local_transcript)
            for opt in options_list:
                target_sent = template.replace("___", opt)
                norm_target = normalize_text(target_sent)
                if norm_target in norm_transcript:
                    local_found.append(opt)
            
            # å¦‚æœæœ¬åœ°æ¯”å°æœ‰æŠ“åˆ°ï¼Œå°±ä½¿ç”¨æœ¬åœ°çµæœ
            if local_found:
                return {
                    "correct_options": local_found,
                    "heard": local_transcript,
                    "feedback": "AI æœªåµæ¸¬åˆ°ï¼Œä½†æœ¬åœ°è¦å‰‡æ¯”å°æˆåŠŸï¼(Fallback)"
                }
            
            # å¦‚æœæœ¬åœ°ä¹Ÿæ²’æŠ“åˆ°ï¼Œä½† Gemini æœ‰å›å‚³ transcriptï¼Œå„ªå…ˆé¡¯ç¤º Gemini çš„è½å¯«çµæœ
            if gemini_success:
                 return {
                    "correct_options": [],
                    "heard": ai_transcript,
                    "feedback": ai_feedback
                }
            
            # åªæœ‰ SR æˆåŠŸï¼ŒGemini å¤±æ•—çš„æƒ…æ³
            return {
                "correct_options": [],
                "heard": local_transcript,
                "feedback": "æœªèƒ½è¾¨è­˜å‡ºæ­£ç¢ºå¥å­ï¼Œè«‹å†è©¦ä¸€æ¬¡ã€‚"
            }
    
    # å…¨éƒ¨å¤±æ•—
    return {
        "correct_options": [],
        "heard": ai_transcript if ai_transcript else "(ç„¡æ³•è¾¨è­˜)",
        "feedback": ai_feedback if ai_feedback else "ç³»çµ±å¿™ç¢Œæˆ–ç„¡æ³•è¾¨è­˜ã€‚"
    }

def call_gemini_to_complete(words_text, course_name, course_date):
    if not words_text.strip(): return []
    
    # --- ä¿®æ”¹é»ï¼šè®€å–å¤–éƒ¨ MD æª”æ¡ˆ ---
    prompt_file = "system_prompt.md"
    if st.secrets.get("system_prompt"):
        base_prompt = st.secrets["system_prompt"]
    elif os.path.exists(prompt_file):
        with open(prompt_file, "r", encoding="utf-8") as f:
            base_prompt = f.read()
    else:
        # å‚™ç”¨ Promptï¼Œé˜²æ­¢æª”æ¡ˆéºå¤±å°è‡´ç¨‹å¼å´©æ½°
        base_prompt = """
You are a vocabulary organizing assistant.
Requirements:
1. Identify the main English word each line.
2. If a line includes definitions or example sentences, CORRECT them if there are errors.
3. If definitions (Chinese_1, Chinese_2), POS, or example sentences are MISSING, provide them.
4. Ensure the Part of Speech (POS) in Traditional Chinese (e.g., åè©, å‹•è©, å½¢å®¹è©).
5. Ensure the (Chinese_1, Chinese_2) in Traditional Chinese.
6. Ensure the (Word, Example) in English.
7. Output format MUST be strictly separated by a pipe symbol (|) for each line.
8. Format: Word | POS | Chinese_1 | Chinese_2 | Example
9. Do not output any header or markdown symbols, just the raw data lines.
        """
    
    prompt = f"{base_prompt}\n\nInput words:\n{words_text}"

    payload = {"contents": [{"parts": [{"text": prompt}]}]}
    try:
        res = requests.post(f"{GEMINI_API_URL}?key={GEMINI_API_KEY}", json=payload, timeout=30)
        if res.status_code == 200:
            text = res.json()['candidates'][0]['content']['parts'][0]['text']
            raw_items = []
            for line in text.strip().split('\n'):
                if '|' in line:
                    p = [i.strip() for i in line.split('|')]
                    if len(p) >= 5:
                        raw_items.append({
                            "English": p[0], "POS": p[1], "Chinese_1": p[2], "Chinese_2": p[3], 
                            "Example": p[4], "Course": course_name, "Date": str(course_date), 
                            "Correct": 0, "Total": 0
                        })
            return raw_items
    except: pass
    return []

def get_combined_dashboard_options(vocab, catalogs):
    options = ["å–®å­— (å…¨éƒ¨)"]
    if vocab:
        df = pd.DataFrame(vocab)
        if 'Course' not in df.columns: df['Course'] = 'æœªåˆ†é¡'
        if 'Date' not in df.columns: df['Date'] = 'N/A'
        unique_courses = sorted(df['Course'].unique())
        for c in unique_courses:
            dates = df[df['Course'] == c]['Date'].unique()
            for d in sorted(dates, reverse=True):
                options.append(f"å–®å­— | {c} | {d}")
    if catalogs:
        catalog_names = list(catalogs.values())
        catalog_ids = list(catalogs.keys())
        for name, cid in zip(catalog_names, catalog_ids):
            options.append(f"å¥å‹ | {name} (å…¨éƒ¨)")
            book_sentences = fetch_sentences_by_id(cid)
            if book_sentences:
                df_b = pd.DataFrame(book_sentences)
                if 'Category' in df_b.columns:
                    cats = sorted(df_b['Category'].unique())
                    for cat in cats:
                        options.append(f"å¥å‹ | {name} | {cat}")
    return options

def get_course_options(vocab):
    if not vocab: return ["å…¨éƒ¨å–®å­—"]
    df = pd.DataFrame(vocab)
    if 'Course' not in df.columns: df['Course'] = 'æœªåˆ†é¡'
    if 'Date' not in df.columns: df['Date'] = 'N/A'
    
    unique_courses = sorted(df['Course'].unique())
    unique_instances = df[['Course', 'Date']].drop_duplicates().sort_values(['Course', 'Date'], ascending=[True, False])
    
    options = ["å…¨éƒ¨å–®å­—"]
    for c in unique_courses:
        options.append(f"ğŸ“š {c} (å…¨éƒ¨)")
        dates = unique_instances[unique_instances['Course'] == c]['Date'].tolist()
        for d in dates:
            options.append(f"   ğŸ“… {c} | {d}")
    return options

def filter_vocab_data(vocab, selection):
    if selection == "å…¨éƒ¨å–®å­—" or not vocab: return vocab
    df = pd.DataFrame(vocab)
    if 'Course' not in df.columns: df['Course'] = 'æœªåˆ†é¡'
    if 'Date' not in df.columns: df['Date'] = 'N/A'

    if "(å…¨éƒ¨)" in selection:
        course_name = selection.replace("ğŸ“š ", "").replace(" (å…¨éƒ¨)", "").strip()
        return df[df['Course'] == course_name].to_dict('records')
    elif "|" in selection:
        parts = selection.replace("   ğŸ“… ", "").split("|")
        if len(parts) >= 2:
            course_name = parts[0].strip()
            course_date = parts[1].strip()
            return df[(df['Course'] == course_name) & (df['Date'] == course_date)].to_dict('records')
    return vocab

def get_sentence_category_options(sentences, catalog_name):
    if not sentences: return [f"ğŸ“š {catalog_name} (å…¨éƒ¨)"]
    df = pd.DataFrame(sentences)
    if 'Category' not in df.columns: df['Category'] = 'æœªåˆ†é¡'
    unique_categories = sorted(df['Category'].unique())
    options = [f"ğŸ“š {catalog_name} (å…¨éƒ¨)"]
    for cat in unique_categories:
        options.append(f"   ğŸ·ï¸ {cat}")
    return options

def filter_sentence_data(sentences, selection):
    if " (å…¨éƒ¨)" in selection: return sentences
    category = selection.replace("   ğŸ·ï¸ ", "").strip()
    return [s for s in sentences if s.get('Category') == category]

def keyboard_bridge():
    js = """<script>
    var doc = window.parent.document;
    window.parent.myKeyHandler = function(e) {
        const getBtn = (txt) => Array.from(doc.querySelectorAll('button')).find(b => b.innerText.includes(txt));
        if (e.key === 'ArrowRight') getBtn("ä¸‹ä¸€å€‹")?.click();
        else if (e.key === 'ArrowLeft') getBtn("ä¸Šä¸€å€‹")?.click();
        else if (e.key === ' ') { e.preventDefault(); getBtn("ç¿»é¢")?.click(); }
    };
    doc.removeEventListener('keydown', window.parent.myKeyHandler);
    doc.addEventListener('keydown', window.parent.myKeyHandler);
    </script>"""
    html(js, height=0)

def auto_focus_input():
    js = """<script>
    setTimeout(() => {
        const doc = window.parent.document;
        const input = Array.from(doc.querySelectorAll('input')).find(i => i.getAttribute('aria-label')?.includes("è¼¸å…¥ä¸­æ–‡"));
        input?.focus();
    }, 250);
    </script>"""
    html(js, height=0)

def text_to_speech(text):
    """
    ç”¢ç”ŸèªéŸ³æ’­æ”¾çš„ HTML å…ƒä»¶ã€‚
    åŒ…å«ä¸€å€‹è‡ªå‹•è§¸ç™¼çš„ Script (é‡å° PC/Android)
    å’Œä¸€å€‹å¯¦é«”æŒ‰éˆ• (é‡å° iOS)
    """
    if not text: return
    safe_text = text.replace('"', '\\"').replace('\n', ' ')
    
    js_code = f"""
    <script>
        function playSound() {{
            var synthesis = window.parent.speechSynthesis || window.speechSynthesis;
            if (synthesis) {{
                synthesis.cancel();
                var msg = new SpeechSynthesisUtterance("{safe_text}");
                msg.lang = 'en-US';
                msg.rate = 0.9;
                synthesis.speak(msg);
            }}
        }}
        setTimeout(playSound, 300);
    </script>
    <style>
        .audio-btn {{
            background-color: transparent; border: 1px solid #ddd; border-radius: 5px;
            padding: 4px 8px; font-size: 12px; cursor: pointer; color: #666;
            display: flex; align-items: center; gap: 4px; margin: 5px auto;
        }}
        .audio-btn:hover {{ background-color: #f0f0f0; color: #333; }}
    </style>
    <div style="display: flex; justify-content: center; width: 100%;">
        <button class="audio-btn" onclick="playSound()">ğŸ”Š æ’­æ”¾ç™¼éŸ³</button>
    </div>
    """
    html(js_code, height=40)

# --- å®¢è£½åŒ–å †ç–Šé€²åº¦æ¢å‡½å¼ (æ°´å¹³æ’åˆ—ç‰ˆï¼Œç„¡æ–‡å­—) ---
def render_custom_progress_bar(label_left, green_pct, yellow_pct, empty_pct):
    """
    ç¹ªè£½ä¸€å€‹ HTML/CSS å †ç–Šé€²åº¦æ¢ï¼Œæ¨™ç±¤èˆ‡é€²åº¦æ¢åœ¨åŒä¸€è¡Œï¼Œç§»é™¤å³å´æ–‡å­—ï¼Œå–æ¶ˆæ·±è‰²å­—é«”é™åˆ¶
    """
    bar_html = f"""
    <div style="display: flex; align-items: center; margin-bottom: 8px;">
        <div style="width: 40px; min-width: 40px; font-size: 0.9rem; margin-right: 10px; white-space: nowrap; overflow: hidden; text-overflow: ellipsis;" title="{label_left}">
            {label_left}
        </div>
        <div style="flex-grow: 1; background-color: #e0e0e0; border-radius: 6px; height: 16px; display: flex; overflow: hidden;">
            <div style="width: {green_pct*100}%; background-color: #28a745; height: 100%;" title="å·²ç†Ÿç·´/å·²å®Œæˆ"></div>
            <div style="width: {yellow_pct*100}%; background-color: #ffc107; height: 100%;" title="ç·´ç¿’ä¸­"></div>
            <div style="width: {empty_pct*100}%; background-color: #e0e0e0; height: 100%;" title="æœªé–‹å§‹"></div>
        </div>
    </div>
    """
    st.markdown(bar_html, unsafe_allow_html=True)

# --- å°èˆªç”¨å›èª¿å‡½å¼ ---
def navigate_to_practice(preset):
    st.session_state.nav_selection = "å–®å­—ç·´ç¿’"
    # å¼·åˆ¶æ›´æ–°ç·´ç¿’é é¢çš„é¸å–®ç‹€æ…‹
    st.session_state["practice_filter"] = preset

# --- å°èˆªç”¨å›èª¿å‡½å¼ (å¥å‹) ---
def navigate_to_sentence(book, cat):
    preset = f"{book} | {cat}"
    st.session_state.sentence_filter_preset = preset
    st.session_state.nav_selection = "å¥å‹å£èªª"
    # å¼·åˆ¶æ›´æ–°å¥å‹é é¢çš„é¸å–®ç‹€æ…‹
    st.session_state["sentence_filter"] = preset

def attempt_login():
    """è™•ç†ç™»å…¥çš„ Callback å‡½å¼"""
    selected_name = st.session_state.login_user_name
    input_password = st.session_state.login_password
    users_db = st.session_state.users_db_cache
    
    if selected_name != "è«‹é¸æ“‡..." and input_password:
        user_record = users_db[selected_name]
        if hash_password(input_password) == user_record["password"]:
            st.session_state.logged_in = True
            st.session_state.current_user_name = selected_name
            st.session_state.user_info = user_record
            st.session_state.login_error = None
            sync_vocab_from_db(init_if_empty=True)
        else:
            st.session_state.login_error = "å¯†ç¢¼éŒ¯èª¤ã€‚"
    else:
        st.session_state.login_error = "è«‹é¸æ“‡ä½¿ç”¨è€…ä¸¦è¼¸å…¥å¯†ç¢¼ã€‚"

# --- 7. UI ä»‹é¢ ---

with st.sidebar:
    col_icon, col_title = st.columns([1, 4])
    col_icon.image("app-icon.png", width=40)
    col_title.markdown("### Flashcard Pro")
    users_db = fetch_users_list()
    # æš«å­˜ä½¿ç”¨è€…åå–®ä»¥ä¾› callback ä½¿ç”¨
    st.session_state.users_db_cache = users_db
    
    if not st.session_state.logged_in:
        st.subheader("ğŸ”‘ å­¸ç”Ÿç™»å…¥")
        
        st.selectbox(
            "è«‹é¸æ“‡ä½¿ç”¨è€…", 
            ["è«‹é¸æ“‡..."] + list(users_db.keys()),
            key="login_user_name"
        )
        
        st.text_input(
            "è¼¸å…¥å¯†ç¢¼", 
            type="password",
            key="login_password",
            on_change=attempt_login
        )
        
        st.button("ç™»å…¥", on_click=attempt_login, use_container_width=True)
        
        if st.session_state.get("login_error"):
            st.error(st.session_state.login_error)
            
    else:
        user = st.session_state.user_info
        st.markdown(f"### ğŸ‘¤ {user['name']}")
        st.caption(f"å­¸è™Ÿ: {user['id']}")
        st.divider()
        # ç¶å®šé¸å–®ç‹€æ…‹è‡³ nav_selection
        menu =st.radio("åŠŸèƒ½é¸å–®", ["å­¸ç¿’å„€è¡¨æ¿", "å–®å­—ç®¡ç†", "å–®å­—ç·´ç¿’", "å¥å‹å£èªª"], key="nav_selection")
        if st.button("ç™»å‡º", use_container_width=True):
            st.session_state.logged_in = False
            st.session_state.user_info = None
            st.session_state.u_vocab = []
            st.rerun()
        
        # --- æ–°å¢ï¼šä¿®æ”¹å¯†ç¢¼ Expander ---
        with st.expander("ğŸ” ä¿®æ”¹å¯†ç¢¼"):
            with st.form("change_pwd_form"):
                curr_pwd = st.text_input("ç›®å‰å¯†ç¢¼", type="password")
                new_pwd = st.text_input("æ–°å¯†ç¢¼", type="password")
                conf_pwd = st.text_input("ç¢ºèªæ–°å¯†ç¢¼", type="password")
                
                if st.form_submit_button("ç¢ºèªä¿®æ”¹"):
                    if hash_password(curr_pwd) != st.session_state.user_info['password']:
                        st.error("ç›®å‰å¯†ç¢¼éŒ¯èª¤ã€‚")
                    elif new_pwd != conf_pwd:
                        st.error("å…©æ¬¡æ–°å¯†ç¢¼è¼¸å…¥ä¸ä¸€è‡´ã€‚")
                    elif not new_pwd:
                        st.error("æ–°å¯†ç¢¼ä¸èƒ½ç‚ºç©ºã€‚")
                    else:
                        # Update Firestore
                        new_hash = hash_password(new_pwd)
                        user_ref = db.collection(USER_LIST_PATH).document(st.session_state.current_user_name)
                        user_ref.update({"password": new_hash})
                        
                        # Update Session State
                        st.session_state.user_info['password'] = new_hash
                        # æ¸…é™¤ä½¿ç”¨è€…åˆ—è¡¨å¿«å–ï¼Œç¢ºä¿ä¸‹æ¬¡ç™»å…¥èƒ½è®€å–åˆ°æ–°å¯†ç¢¼
                        fetch_users_list.clear()
                        
                        st.success("å¯†ç¢¼ä¿®æ”¹æˆåŠŸï¼")
                        time.sleep(1)

# --- æ³¨å…¥ CSS ä»¥å½è£ Button ç‚ºç´”æ–‡å­— (åŠ å¼·ç‰ˆ) ---
st.markdown("""
<style>
/* å°‡ Expander å…§çš„æŒ‰éˆ•å½è£æˆç´”æ–‡å­— */
div[data-testid="stExpander"] [data-testid="stButton"] button {
    border: none !important;
    background: transparent !important;
    color: inherit !important;
    text-decoration: none !important;
    padding: 0px !important;
    margin: 0px !important;
    height: auto !important;
    min-height: 0px !important;
    line-height: normal !important;
    font-size: 0.9rem !important;
    cursor: pointer !important;
    text-align: left !important;
    display: inline-block !important;
}

div[data-testid="stExpander"] button:hover {
    text-decoration: underline !important; /* æ»‘é¼ ç§»éæ™‚åŠ åº•ç·šä½œç‚ºæç¤º */
    color: #555 !important;
}

div[data-testid="stExpander"] button:focus {
    box-shadow: none !important;
    outline: none !important;
}
</style>
""", unsafe_allow_html=True)

if not st.session_state.logged_in:
    st.title("ğŸš€ æ­¡è¿ä½¿ç”¨ Flashcard Pro")
    st.info("è«‹ç™»å…¥ä»¥é–‹å§‹ç·´ç¿’ã€‚é è¨­å¯†ç¢¼ 1234ã€‚")
    
    st.divider()

    c_title, c_refresh = st.columns([8, 2])
    c_title.subheader("ğŸ† å…¨ç­å¥å‹ç·´ç¿’æ’è¡Œæ¦œ")
    if c_refresh.button("ğŸ”„ åˆ·æ–°æ•¸æ“š"):
        st.cache_data.clear()
        st.rerun()

    # è®€å–æ’è¡Œæ¦œæ•¸æ“šï¼ŒæŒ‰å¥å‹æ›¸åˆ†çµ„
    all_users = fetch_users_list()

    # çµæ§‹: { book_name: [ {å­¸ç”Ÿ, completed, total, rate, last_active}, ... ] }
    books_data = {}

    for uid, u_data in all_users.items():
        s_stats = u_data.get("sentence_stats", {})
        if not s_stats: continue

        for book_id, stat in s_stats.items():
            if not isinstance(stat, dict): continue
            total = stat.get('total', 0)
            if total == 0: continue

            completed = stat.get('completed', 0)
            book_name = stat.get('name', book_id)

            # å°‡ Timestamp è½‰æ›ç‚ºå­—ä¸²
            last_active = stat.get('last_active')
            if hasattr(last_active, 'date'):
                last_active_str = last_active.strftime("%m-%d %H:%M")
            else:
                last_active_str = str(last_active) if last_active else ""

            if book_name not in books_data:
                books_data[book_name] = []

            books_data[book_name].append({
                "student": u_data.get('name', uid),
                "completed": completed,
                "total": total,
                "rate": completed / total if total > 0 else 0,
                "last_active": last_active_str
            })

    if books_data:
        for book_name, students in books_data.items():
            # æŒ‰å®Œæˆç‡æ’åºï¼ˆé«˜åˆ°ä½ï¼‰
            students_sorted = sorted(students, key=lambda x: (-x['rate'], -x['completed']))

            st.markdown(f"#### ğŸ“˜ {book_name}")

            for rank, s in enumerate(students_sorted, 1):
                pct = int(s['rate'] * 100)
                # å‰ä¸‰åä½¿ç”¨çç‰Œ emoji
                if rank == 1:
                    rank_display = "ğŸ¥‡"
                elif rank == 2:
                    rank_display = "ğŸ¥ˆ"
                elif rank == 3:
                    rank_display = "ğŸ¥‰"
                else:
                    rank_display = f"{rank}."

                bar_html = f"""
                <div style="display: flex; align-items: center; margin-bottom: 6px; font-size: 0.9rem;">
                    <div style="width: 80px; min-width: 80px;">{rank_display} {s['student']}</div>
                    <div style="flex-grow: 1; background-color: #e0e0e0; border-radius: 6px; height: 14px; margin: 0 10px; overflow: hidden;">
                        <div style="width: {pct}%; background-color: #4CAF50; height: 100%;"></div>
                    </div>
                    <div style="width: 60px; min-width: 60px; text-align: right;">{s['completed']}/{s['total']}</div>
                    <div style="width: 90px; min-width: 90px; text-align: right; color: #888; font-size: 0.8rem;">{s['last_active']}</div>
                </div>
                """
                st.markdown(bar_html, unsafe_allow_html=True)

            st.write("")  # é–“éš”
    else:
        st.info("ç›®å‰é‚„æ²’æœ‰äººé–‹å§‹ç·´ç¿’å¥å‹ï¼Œå¿«ç™»å…¥æˆç‚ºç¬¬ä¸€åï¼")

else:
    u_vocab = st.session_state.u_vocab

    if menu == "å­¸ç¿’å„€è¡¨æ¿":
        st.title("ğŸ“Š å­¸ç¿’å„€è¡¨æ¿")
        
        # èª¿æ•´ Tab é †åºï¼šå­¸ç¿’æˆ°ç¸¾è¡¨(åŸç¸½è¡¨)åœ¨ç¬¬ä¸€ä½
        tab_total, tab_v, tab_s = st.tabs(["å­¸ç¿’æˆ°ç¸¾è¡¨", "å–®å­—å­¸ç¿’", "å¥å‹ç·´ç¿’"])
        
        # --- å­¸ç¿’æˆ°ç¸¾è¡¨ Tab (æ–°è¨­è¨ˆ) ---
        with tab_total:
            st.subheader("ğŸ“ˆ å­¸ç¿’æˆ°ç¸¾è¡¨")
            
            # 1. å–®å­—æ¦‚æ³ (Stacked Bar)
            st.markdown("#### ğŸ“š å–®å­—èª²ç¨‹é€²åº¦")
            if u_vocab:
                df_v = pd.DataFrame(u_vocab)
                if 'Course' not in df_v.columns: df_v['Course'] = 'æœªåˆ†é¡'
                if 'Date' not in df_v.columns: df_v['Date'] = 'N/A'
                
                courses = sorted(df_v['Course'].unique())
                for course in courses:
                    with st.expander(f"ğŸ“˜ {course}", expanded=True):
                        c_data = df_v[df_v['Course'] == course]
                        dates = sorted(c_data['Date'].unique(), reverse=True)
                        for d in dates:
                            d_data = c_data[c_data['Date'] == d]
                            total = len(d_data)
                            
                            mastered = len(d_data[d_data['Correct'] > 0])
                            learning = len(d_data[(d_data['Total'] > 0) & (d_data['Correct'] == 0)])
                            
                            p_mastered = mastered / total if total > 0 else 0
                            p_learning = learning / total if total > 0 else 0
                            p_empty = 1 - p_mastered - p_learning
                            
                            c1, c2 = st.columns([2, 8])
                            # å–®å­—æŒ‰éˆ•
                            c1.button(
                                f"ğŸ“… {d}", 
                                key=f"btn_vocab_{course}_{d}",
                                on_click=navigate_to_practice,
                                kwargs={"preset": f"   ğŸ“… {course} | {d}"}
                            )
                            with c2:
                                render_custom_progress_bar(f"({total}å€‹)", p_mastered, p_learning, p_empty)
            else: st.info("å°šç„¡å–®å­—è³‡æ–™ã€‚")

            st.divider()

            # 2. å¥å‹æ¦‚æ³ (Stacked Bar)
            st.markdown("#### ğŸ—£ï¸ å¥å‹æ›¸é€²åº¦")
            catalogs = fetch_sentence_catalogs()
            if catalogs:
                catalog_names = list(catalogs.values())
                catalog_ids = list(catalogs.keys())
                user_progress = fetch_all_user_sentence_progress()
                
                for name, cid in zip(catalog_names, catalog_ids):
                    b_sentences = fetch_sentences_by_id(cid)
                    if not b_sentences: continue
                    
                    with st.expander(f"ğŸ“™ {name}", expanded=True):
                        df_s = pd.DataFrame(b_sentences)
                        if 'Category' not in df_s.columns: df_s['Category'] = 'æœªåˆ†é¡'
                        cats = sorted(df_s['Category'].unique())
                        
                        for cat in cats:
                            cat_sents = [s for s in b_sentences if s.get('Category') == cat]
                            tot = len(cat_sents)
                            
                            cnt_done = 0
                            cnt_progress = 0
                            
                            for s in cat_sents:
                                h = hash_string(s['Template'])
                                user_done = user_progress.get(h, [])
                                s_opts = s.get('Options', [])
                                
                                if not s_opts: continue
                                
                                intersection = len(set(s_opts).intersection(set(user_done)))
                                if intersection == len(s_opts):
                                    cnt_done += 1
                                elif intersection > 0:
                                    cnt_progress += 1
                            
                            p_done = cnt_done / tot if tot > 0 else 0
                            p_prog = cnt_progress / tot if tot > 0 else 0
                            p_empty = 1 - p_done - p_prog
                            
                            c1, c2 = st.columns([2, 8])
                            # å¥å‹æŒ‰éˆ•
                            c1.button(
                                f"ğŸ·ï¸ {cat}",
                                key=f"btn_sent_{name}_{cat}",
                                on_click=navigate_to_sentence,
                                kwargs={"book": name, "cat": cat}
                            )
                            with c2:
                                render_custom_progress_bar(f"({tot}å¥)", p_done, p_prog, p_empty)

        # --- å–®å­— Tab ---
        with tab_v:
            if not u_vocab:
                st.info("å°šç„¡å–®å­—è³‡æ–™ã€‚")
                if st.button("ğŸ”„ åŒæ­¥é›²ç«¯"): sync_vocab_from_db(); st.rerun()
            else:
                options = get_course_options(u_vocab)
                # ç›´æ¥ä½¿ç”¨ key="vocab_dash_filter" å¾ session state å–å€¼ï¼Œä¸ä½¿ç”¨ index
                selection = st.selectbox("å–®å­—ç¯©é¸ç¯„åœï¼š", options, key="vocab_dash_filter")
                
                filtered_vocab = filter_vocab_data(u_vocab, selection)
                
                col1, col2, col3 = st.columns(3)
                
                # Metric 1: ç¸½å–®å­—æ•¸
                total_vocab_count = len(filtered_vocab)
                col1.metric("ç¯„åœå…§å–®å­—æ•¸", total_vocab_count)
                
                # Metric 2: ç·´ç¿’è¦†è“‹ç‡ (æœ‰åšéç·´ç¿’çš„å–®å­—æ•¸ / ç¸½å–®å­—æ•¸)
                practiced_count = len([v for v in filtered_vocab if v.get('Total', 0) > 0])
                coverage_rate = (practiced_count / total_vocab_count * 100) if total_vocab_count > 0 else 0
                col2.metric("ç·´ç¿’è¦†è“‹ç‡", f"{coverage_rate:.1f}%", help="æœ‰ç·´ç¿’éçš„å–®å­—æ¯”ä¾‹")
                
                # Metric 3: ç­”é¡Œæ­£ç¢ºç‡ (ç¸½ç­”å° / ç¸½ç­”é¡Œ) -> å“è³ªæŒ‡æ¨™
                total_correct = sum(v.get('Correct', 0) for v in filtered_vocab)
                total_attempts = sum(v.get('Total', 0) for v in filtered_vocab)
                accuracy_rate = (total_correct / total_attempts * 100) if total_attempts > 0 else 0
                col3.metric("ç­”é¡Œæ­£ç¢ºç‡", f"{accuracy_rate:.1f}%", help="æ‰€æœ‰ç·´ç¿’æ¬¡æ•¸ä¸­çš„æ­£ç¢ºæ¯”ä¾‹")
                
                st.divider()
                st.dataframe(pd.DataFrame(filtered_vocab)[['English', 'Chinese_1', 'POS', 'Course', 'Date', 'Correct', 'Total']], use_container_width=True, hide_index=True)

        # --- å¥å‹ Tab ---
        with tab_s:
            catalogs = fetch_sentence_catalogs()
            if not catalogs:
                st.info("å°šç„¡å¥å‹è³‡æ–™åº«ã€‚")
            else:
                # æº–å‚™é¸å–®
                catalog_names = list(catalogs.values())
                catalog_ids = list(catalogs.keys())
                
                combined_s_options = []
                # æ›¸å -> ID å°ç…§
                book_map = {name: cid for cid, name in catalogs.items()}

                for name, cid in zip(catalog_names, catalog_ids):
                    combined_s_options.append(f"{name} (å…¨éƒ¨)")
                    book_sentences = fetch_sentences_by_id(cid)
                    if book_sentences:
                        df_b = pd.DataFrame(book_sentences)
                        if 'Category' in df_b.columns:
                            cats = sorted(df_b['Category'].unique())
                            for c in cats:
                                combined_s_options.append(f"{name} | {c}")
                
                # ç›´æ¥ä½¿ç”¨ key="sentence_dash_filter" å¾ session state å–å€¼ï¼Œä¸ä½¿ç”¨ index
                s_selection = st.selectbox("å¥å‹ç¯©é¸ç¯„åœï¼š", combined_s_options, key="sentence_dash_filter")
                
                if " (å…¨éƒ¨)" in s_selection:
                    book_name = s_selection.replace(" (å…¨éƒ¨)", "")
                    target_id = book_map.get(book_name)
                    target_sentences = fetch_sentences_by_id(target_id)
                else:
                    book_name, category = s_selection.split(" | ")
                    target_id = book_map.get(book_name)
                    all_sentences = fetch_sentences_by_id(target_id)
                    target_sentences = [s for s in all_sentences if s.get('Category') == category]
                
                if not target_sentences:
                    st.info("ç„¡å¥å‹è³‡æ–™ã€‚")
                else:
                    # çµ±è¨ˆæ•¸æ“š
                    user_progress = fetch_all_user_sentence_progress()
                    
                    total_s_count = len(target_sentences)
                    fully_completed_count = 0
                    
                    progress_table = []
                    
                    for s in target_sentences:
                        h = hash_string(s['Template'])
                        user_done = user_progress.get(h, [])
                        s_opts = s.get('Options', [])
                        
                        is_done = set(s_opts).issubset(set(user_done))
                        if is_done: fully_completed_count += 1
                        
                        progress_table.append({
                            "åˆ†é¡": s.get('Category', ''),
                            "å¥å‹": s['Template'],
                            "é¸é …æ•¸": len(s_opts),
                            "å·²å®Œæˆ": len(set(s_opts).intersection(set(user_done))),
                            "ç‹€æ…‹": "âœ…" if is_done else "ğŸ’ª"
                        })
                    
                    sc1, sc2, sc3 = st.columns(3)
                    sc1.metric("ç¸½å¥æ•¸", total_s_count)
                    sc2.metric("å·²å®Œæˆå¥æ•¸", fully_completed_count)
                    s_rate = (fully_completed_count / total_s_count * 100) if total_s_count > 0 else 0
                    sc3.metric("å®Œæˆç‡", f"{s_rate:.1f}%")

                    st.divider()
                    st.dataframe(pd.DataFrame(progress_table), use_container_width=True, hide_index=True)
                    
                    # --- æ–°å¢ï¼šæ¸…é™¤ç´€éŒ„æŒ‰éˆ• ---
                    if st.button("ğŸ—‘ï¸ æ¸…é™¤æ‰€æœ‰å¥å‹ç·´ç¿’ç´€éŒ„ (ç„¡æ³•å¾©åŸ)", type="primary"):
                        clear_user_sentence_history(target_id)
                        st.success("å·²æ¸…é™¤æ‰€æœ‰é€²åº¦ï¼")
                        time.sleep(1)
                        st.rerun()


    elif menu == "å–®å­—ç®¡ç†":
        st.title("âš™ï¸ å–®å­—ç®¡ç†")
        tab1, tab2, tab3, tab4 = st.tabs(["æ‰¹æ¬¡è¼¸å…¥", "æ‰‹å‹•ä¿®æ”¹", "å–®å­—åˆªé™¤", "ğŸ“‚ CSV åŒ¯å…¥"])
        
        with tab1:
            c_name = st.text_input("èª²ç¨‹åç¨±:", value="æ–°èª²ç¨‹")
            c_date = st.date_input("æ—¥æœŸ:", value=date.today())
            text_area = st.text_area("è¼¸å…¥å…§å®¹:")
            if st.button("å•Ÿå‹• AI è™•ç†"):
                with st.spinner("è§£æä¸­..."):
                    st.session_state.pending_items = call_gemini_to_complete(text_area, c_name, c_date)
            if st.session_state.get("pending_items"):
                edited = st.data_editor(pd.DataFrame(st.session_state.pending_items), use_container_width=True, hide_index=True)
                if st.button("ğŸ’¾ ç¢ºèªå„²å­˜", type="primary"):
                    path = get_vocab_path()
                    for it in edited.to_dict('records'): db.collection(path).add(it)
                    st.session_state.pending_items = None
                    sync_vocab_from_db(); st.success("å„²å­˜æˆåŠŸï¼"); st.rerun()
        
        with tab2:
            if u_vocab:
                opts = get_course_options(u_vocab)
                sel = st.selectbox("è«‹é¸æ“‡ä¿®æ”¹ç¯„åœï¼š", opts, key="edit_filter")
                filtered = filter_vocab_data(u_vocab, sel)
                if filtered:
                    edited_df = st.data_editor(pd.DataFrame(filtered), column_order=["English", "Group", "Chinese_1", "Chinese_2", "Example"], use_container_width=True, hide_index=True)
                    if st.button("ğŸ’¾ å„²å­˜ä¿®æ”¹"):
                        for _, row in edited_df.iterrows(): update_word_data(row.get('id'), {k: v for k, v in row.to_dict().items() if k != 'id'})
                        st.success("æ›´æ–°å®Œæˆï¼"); st.rerun()
                else: st.warning("é¸å–ç¯„åœå…§ç„¡å–®å­—ã€‚")
            else: st.info("ç„¡å–®å­—è³‡æ–™ã€‚")

        with tab3:
            if u_vocab:
                opts = get_course_options(u_vocab)
                sel = st.selectbox("è«‹é¸æ“‡åˆªé™¤ç¯„åœï¼š", opts, key="delete_filter")
                filtered = filter_vocab_data(u_vocab, sel)
                if filtered:
                    # åŠ å…¥å…¨é¸ Checkbox
                    col_check, _ = st.columns([1, 6])
                    with col_check:
                        select_all = st.checkbox("å…¨é¸", value=False, key="del_select_all")
                    
                    df_del = pd.DataFrame(filtered)
                    # æ ¹æ“š Checkbox è¨­å®šé è¨­å€¼
                    df_del.insert(0, "é¸å–", select_all)
                    
                    res = st.data_editor(
                        df_del[['é¸å–', 'id', 'English', 'Chinese_1', 'Course']], 
                        column_config={"id": None}, 
                        use_container_width=True, 
                        hide_index=True
                    )
                    
                    to_delete = res[res["é¸å–"] == True]["id"].tolist()
                    if st.button(f"ç¢ºèªåˆªé™¤ ({len(to_delete)} å€‹)", type="primary"):
                        delete_words_from_db(to_delete)
                        sync_vocab_from_db(); st.success("å·²åˆªé™¤ï¼"); st.rerun()
                else: st.warning("ç„¡è³‡æ–™ã€‚")
            else: st.info("ç„¡è³‡æ–™ã€‚")

        with tab4:
            st.subheader("ğŸ“‚ å¾ CSV æª”æ¡ˆåŒ¯å…¥")
            uploaded_file = st.file_uploader("é¸æ“‡ CSV æª”æ¡ˆ", type=["csv"])
            col_a, col_b = st.columns(2)
            default_course = col_a.text_input("é è¨­èª²ç¨‹åç¨±", "åŒ¯å…¥å–®å­—")
            default_date = col_b.date_input("é è¨­æ—¥æœŸ", value=date.today())
            
            if uploaded_file is not None:
                try:
                    df_csv = pd.read_csv(uploaded_file)
                    st.write(f"é è¦½ä¸Šå‚³å…§å®¹ (å…± {len(df_csv)} ç­†)ï¼š")
                    st.dataframe(df_csv)
                    
                    if "English" in df_csv.columns and "Chinese_1" in df_csv.columns:
                        if st.button("ğŸš€ é–‹å§‹åŒ¯å…¥è³‡æ–™åº«", type="primary"):
                            with st.spinner("æ­£åœ¨åŒ¯å…¥..."):
                                df_csv = df_csv.fillna("")
                                items_to_add = []
                                for _, row in df_csv.iterrows():
                                    # CSV åŒ¯å…¥ä¹Ÿæ”¹ç‚ºè®€å– POS
                                    pos_val = str(row.get("POS", str(row.get("Group", "")))).strip()
                                    if not pos_val: pos_val = "æœªåˆ†é¡"
                                    
                                    course_val = str(row.get("Course", "")).strip()
                                    if not course_val: course_val = default_course
                                    
                                    date_val = str(row.get("Date", "")).strip()
                                    if not date_val: date_val = str(default_date)

                                    item = {
                                        "English": str(row.get("English", "")),
                                        "Chinese_1": str(row.get("Chinese_1", "")),
                                        "Chinese_2": str(row.get("Chinese_2", "")),
                                        "POS": pos_val,
                                        "Example": str(row.get("Example", "")),
                                        "Course": course_val,
                                        "Date": date_val,
                                        "Correct": int(row.get("Correct", 0)) if str(row.get("Correct", "0")).isdigit() else 0,
                                        "Total": int(row.get("Total", 0)) if str(row.get("Total", "0")).isdigit() else 0
                                    }
                                    items_to_add.append(item)
                                save_new_words_to_db(items_to_add)
                                sync_vocab_from_db()
                                st.success(f"æˆåŠŸåŒ¯å…¥ {len(items_to_add)} ç­†å–®å­—ï¼")
                                time.sleep(1)
                                st.rerun()
                    else:
                        st.error("CSV æ ¼å¼éŒ¯èª¤ï¼šå¿…é ˆåŒ…å« 'English' èˆ‡ 'Chinese_1' æ¬„ä½ã€‚")
                except Exception as e:
                    st.error(f"è®€å–æª”æ¡ˆå¤±æ•—: {e}")

    elif menu == "å–®å­—ç·´ç¿’":
        st.title("âœï¸ å–®å­—ç·´ç¿’")
        options = get_course_options(u_vocab)
        # ç›´æ¥ä½¿ç”¨ key="practice_filter" å¾ session state å–å€¼ï¼Œä¸ä½¿ç”¨ index
        selection = st.selectbox("ğŸ¯ é¸æ“‡ç·´ç¿’ç¯„åœï¼š", options, key="practice_filter")
        
        current_set = filter_vocab_data(u_vocab, selection)
        
        tab_p, tab_t = st.tabs(["å¿«é–ƒç·´ç¿’", "å¯¦åŠ›æ¸¬é©—"])
        
        with tab_p:
            if not current_set: st.info("ç¯„åœå…§ç„¡å–®å­—ã€‚")
            else:
                if st.session_state.practice_idx >= len(current_set): st.session_state.practice_idx = 0
                target = current_set[st.session_state.practice_idx]
                
                with st.container(border=True):
                    st.caption(f"{target.get('Course')} | {st.session_state.practice_idx + 1}/{len(current_set)}")
                    st.header(target['English'])
                    
                    if not st.session_state.practice_reveal:
                        text_to_speech(target['English'])
                    if st.session_state.practice_reveal:
                        text_to_speech(target.get('Example', ''))
                    
                    if st.session_state.practice_reveal:
                        st.divider()
                        st.markdown(f"**ä¸­æ–‡ï¼š** {target['Chinese_1']} ({target.get('POS')})")
                        st.info(f"ä¾‹å¥ï¼š{target.get('Example', '')}")
                    st.write("")
                    c1, c2, c3 = st.columns(3)
                    
                    if c1.button("ä¸Šä¸€å€‹", use_container_width=True):
                        st.session_state.practice_idx = (st.session_state.practice_idx-1)%len(current_set)
                        st.session_state.practice_reveal=False
                        st.session_state.audio_to_play = current_set[st.session_state.practice_idx]['English']
                        st.rerun()
                        
                    if c2.button("ç¿»é¢", use_container_width=True):
                        st.session_state.practice_reveal = not st.session_state.practice_reveal
                        if st.session_state.practice_reveal:
                            st.session_state.audio_to_play = target.get('Example', '')
                        st.rerun()
                        
                    if c3.button("ä¸‹ä¸€å€‹", use_container_width=True):
                        st.session_state.practice_idx = (st.session_state.practice_idx+1)%len(current_set)
                        st.session_state.practice_reveal=False
                        st.session_state.audio_to_play = current_set[st.session_state.practice_idx]['English']
                        st.rerun()
                keyboard_bridge()

        with tab_t:
            if st.session_state.get("show_test_toast"):
                st.toast("âœ… æ­£ç¢ºï¼"); st.session_state.show_test_toast = False
            
            if not current_set: st.info("ç¯„åœå…§ç„¡å–®å­—ã€‚")
            else:
                if "test_pool" not in st.session_state or st.button("æ›ä¸€æ‰¹é¡Œç›®"):
                    st.session_state.test_pool = random.sample(current_set, min(10, len(current_set)))
                    st.session_state.t_idx = 0; st.session_state.t_score = 0; st.session_state.quiz_history = []
                    st.rerun()
                
                if st.session_state.t_idx < len(st.session_state.test_pool):
                    curr = st.session_state.test_pool[st.session_state.t_idx]
                    with st.form(key=f"q_f_{st.session_state.t_idx}", border=True):
                        st.caption(f"é€²åº¦ï¼š{st.session_state.t_idx + 1} / {len(st.session_state.test_pool)}")
                        st.header(curr['English'])
                        ans = st.text_input("è¼¸å…¥ä¸­æ–‡ï¼š")
                        if st.form_submit_button("æäº¤", use_container_width=True):
                            ok = ans and (ans in str(curr['Chinese_1']) or str(curr['Chinese_1']) in ans)
                            st.session_state.quiz_history.append({"è‹±æ–‡": curr['English'], "ä½ çš„è¼¸å…¥": ans, "æ­£ç¢ºç­”æ¡ˆ": curr['Chinese_1'], "is_correct": ok})
                            if ok: st.session_state.t_score += 1
                            update_word_data(curr.get('id'), {"Correct": int(curr.get('Correct', 0)) + (1 if ok else 0), "Total": int(curr.get('Total', 0)) + 1})
                            st.session_state.t_idx += 1; st.rerun()
                    auto_focus_input()
                else:
                    st.success(f"æ¸¬é©—å¾—åˆ†ï¼š{st.session_state.t_score} / {len(st.session_state.test_pool)}")
                    df_h = pd.DataFrame(st.session_state.quiz_history)
                    wrongs = df_h[df_h["is_correct"] == False]
                    if not wrongs.empty:
                        st.subheader("âŒ éŒ¯èª¤å›é¡§")
                        st.table(wrongs[["è‹±æ–‡", "ä½ çš„è¼¸å…¥", "æ­£ç¢ºç­”æ¡ˆ"]])

    elif menu == "å¥å‹å£èªª":
        st.title("ğŸ—£ï¸ å¥å‹å£èªªæŒ‘æˆ°")
        catalogs = fetch_sentence_catalogs()
        if not catalogs:
            st.info("ç›®å‰é›²ç«¯æ²’æœ‰å¥å‹è³‡æ–™åº«ã€‚")
            if INITIAL_SENTENCES:
                st.warning("âš ï¸ ä½¿ç”¨é è¨­é¡Œåº«æ¨¡å¼ (æœªé€£çµé›²ç«¯)"); current_sentences = INITIAL_SENTENCES
            else: st.stop()
        else:
            catalog_names = list(catalogs.values())
            catalog_ids = list(catalogs.keys())
            
            combined_options = []
            book_map = {name: cid for cid, name in catalogs.items()}

            for name, cid in zip(catalog_names, catalog_ids):
                combined_options.append(f"{name} (å…¨éƒ¨)")
                book_sentences = fetch_sentences_by_id(cid)
                if book_sentences:
                    df_b = pd.DataFrame(book_sentences)
                    if 'Category' in df_b.columns:
                        cats = sorted(df_b['Category'].unique())
                        for c in cats:
                            combined_options.append(f"{name} | {c}")
            
            # ç›´æ¥ä½¿ç”¨ key="sentence_filter" å¾ session state å–å€¼ï¼Œä¸ä½¿ç”¨ index
            selection = st.selectbox("é¸æ“‡ç·´ç¿’ç¯„åœï¼š", combined_options, key="sentence_filter")
            
            if " (å…¨éƒ¨)" in selection:
                book_name = selection.replace(" (å…¨éƒ¨)", "")
                target_id = book_map.get(book_name)
                current_sentences = fetch_sentences_by_id(target_id)
                # è¨˜éŒ„ç•¶å‰é¡Œåº« ID ä¾›å„²å­˜æ™‚ä½¿ç”¨
                st.session_state.current_dataset_id = target_id
            else:
                book_name, category = selection.split(" | ")
                target_id = book_map.get(book_name)
                # è¨˜éŒ„ç•¶å‰é¡Œåº« ID ä¾›å„²å­˜æ™‚ä½¿ç”¨
                st.session_state.current_dataset_id = target_id
                all_book_sentences = fetch_sentences_by_id(target_id)
                current_sentences = [s for s in all_book_sentences if s.get('Category') == category]
        
        if not current_sentences: st.info("æ­¤ç¯„åœå…§ç„¡é¡Œç›®ã€‚")
        else:
            # æ™ºæ…§è·³è½‰ï¼šå¦‚æœæ˜¯å‰›é€²å…¥é é¢ï¼ˆæˆ–åˆ‡æ›é¡Œåº«ï¼‰ï¼Œå˜—è©¦è·³åˆ°ç¬¬ä¸€é¡Œæœªå®Œæˆçš„
            # æˆ‘å€‘ç”¨ session_state.last_sentence_filter_sig ä¾†åˆ¤æ–·æ˜¯å¦åˆ‡æ›äº†é¡Œåº«
            current_filter_sig = selection
            if st.session_state.last_sentence_filter_sig != current_filter_sig:
                # åˆ‡æ›äº†é¡Œåº«ï¼Œå°‹æ‰¾ç¬¬ä¸€å€‹æœªå®Œæˆçš„
                user_progress = fetch_all_user_sentence_progress()
                found_idx = 0
                for i, s in enumerate(current_sentences):
                    h = hash_string(s['Template'])
                    done = user_progress.get(h, [])
                    opts = s.get('Options', [])
                    if not set(opts).issubset(set(done)):
                        found_idx = i
                        break
                st.session_state.sentence_idx = found_idx
                st.session_state.completed_options = set() # é‡ç½®ç•¶å‰é¡Œç›®çš„å®Œæˆç‹€æ…‹
                st.session_state.last_sentence_filter_sig = current_filter_sig
                if "loaded_hash" in st.session_state: del st.session_state.loaded_hash
            
            # ç¢ºä¿ç´¢å¼•ä¸è¶Šç•Œ
            if st.session_state.sentence_idx >= len(current_sentences):
                st.session_state.sentence_idx = 0
            
            curr_sent = current_sentences[st.session_state.sentence_idx]
            template = curr_sent['Template']
            options = curr_sent['Options']
            
            template_hash = hash_string(template)
            if "loaded_hash" not in st.session_state or st.session_state.loaded_hash != template_hash:
                st.session_state.completed_options = load_user_sentence_progress(template_hash)
                st.session_state.loaded_hash = template_hash

            progress_placeholder = st.empty()
            def render_progress():
                c = len(st.session_state.completed_options); t = len(options)
                progress_placeholder.progress(c / t, text=f"å®Œæˆé€²åº¦: {c}/{t}")
            render_progress()
            
            st.subheader(f"é¡Œç›® ({curr_sent.get('Category', 'ä¸€èˆ¬')})")
            st.markdown(f"### {template}", unsafe_allow_html=True)
            
            options_placeholder = st.empty()
            def render_options_status():
                with options_placeholder.container():
                    st.caption("è«‹ä¸€å£æ°£å”¸å‡ºåŒ…å«ä¸‹æ–¹æ‰€æœ‰å–®å­—çš„å¥å­ï¼š")
                    cols = st.columns(len(options))
                    for i, opt in enumerate(options):
                        if opt in st.session_state.completed_options: cols[i].success(f"âœ… {opt}")
                        else: cols[i].info(f"{opt}")
            render_options_status()
            
            st.divider()
            st.write("è«‹æŒ‰ä¸‹éŒ„éŸ³ï¼Œä¸¦å˜—è©¦å”¸å‡ºæ‰€æœ‰å¥å­ (ä¾‹å¦‚: This test is very important. This rule is...)")
            audio_val = st.audio_input("ğŸ”´ é»æ“Šé–‹å§‹éŒ„éŸ³", key=f"rec_{st.session_state.sentence_idx}")
            
            if audio_val:
                with st.spinner("AI æ­£åœ¨åˆ†ææ‚¨çš„éŒ„éŸ³..."):
                    remaining = [opt for opt in options if opt not in st.session_state.completed_options]
                    if not remaining: st.success("æœ¬é¡Œå·²å…¨éƒ¨å®Œæˆï¼")
                    else:
                        result = check_audio_batch(audio_val, template, options)
                        new_corrects = result.get("correct_options", [])
                        if new_corrects:
                            for nc in new_corrects:
                                if nc in options: st.session_state.completed_options.add(nc)
                            save_user_sentence_progress(template, st.session_state.completed_options, dataset_id=st.session_state.current_dataset_id)
                            st.success(f"ğŸ‰ è¾¨è­˜å‡ºï¼š{', '.join(new_corrects)}")
                            render_options_status(); render_progress() 
                            if len(st.session_state.completed_options) == len(options): st.balloons()                            
                        else:
                            st.warning("ğŸ¤” ä¼¼ä¹æ²’æœ‰è¾¨è­˜åˆ°æ–°çš„æ­£ç¢ºå¥å­ï¼Œè«‹å†è©¦ä¸€æ¬¡ã€‚")
                        with st.expander("æŸ¥çœ‹å®Œæ•´è½å¯«å…§å®¹", expanded=True):
                            st.write(result.get("heard"))
                            st.caption(f"AI å»ºè­°: {result.get('feedback')}")
            
            st.write("")
            c1, c2 = st.columns(2)
            if c1.button("â† ä¸Šä¸€é¡Œ", use_container_width=True):
                st.session_state.sentence_idx = (st.session_state.sentence_idx - 1) % len(current_sentences)
                st.session_state.completed_options = set()
                del st.session_state.loaded_hash
                st.rerun()
            if c2.button("ä¸‹ä¸€é¡Œ â†’", use_container_width=True):
                st.session_state.sentence_idx = (st.session_state.sentence_idx + 1) % len(current_sentences)
                st.session_state.completed_options = set()
                del st.session_state.loaded_hash
                st.rerun()
            
            keyboard_bridge()

st.divider()
st.caption("Flashcard Pro - è³‡æ–™å·²åŠ å¯†ä¸¦åŒæ­¥è‡³ Firestore")